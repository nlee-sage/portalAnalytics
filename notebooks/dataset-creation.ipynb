{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toolbox  # my own little package I made to help with curation work\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 375598         \n",
      "Percentage of original dataframe 71.62%\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"../data/cleaned-data-20231215.csv\"\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# Feature selection\n",
    "df = df.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"ID\",\n",
    "        \"TYPE\",\n",
    "        \"TABLE\",\n",
    "        \"NAME\",\n",
    "        \"FILEFORMAT\",\n",
    "        \"STUDY\",\n",
    "        \"ASSAY\",\n",
    "        \"DATATYPE\",\n",
    "        \"DATASUBTYPE\",\n",
    "        \"RESOURCETYPE\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "# Explode list columns into rows\n",
    "df[\"ASSAY\"] = df[\"ASSAY\"].str.split(\",\")\n",
    "df = df.explode(\"ASSAY\")\n",
    "\n",
    "\n",
    "og_shape = df.shape\n",
    "# print(\"Original dataset info\")\n",
    "# df.info()\n",
    "\n",
    "# focusing on file annotations first\n",
    "df = df[df[\"TYPE\"] != \"folder\"]\n",
    "\n",
    "# drop any missing values to develop training/test sets\n",
    "df_full = df.dropna(how=\"any\")\n",
    "new_shape = df_full.shape\n",
    "\n",
    "\n",
    "df.loc[~df.index.isin(df_full.index),].to_csv(\n",
    "    f\"../data/testing-dataset-withNulls-{today}.csv\"\n",
    ")\n",
    "# print(\"-\" * 50)\n",
    "# print(\"New dataset info\")\n",
    "# df_full.info()\n",
    "\n",
    "# print(\"-\" * 50)\n",
    "print(\n",
    "    f\"Rows removed: {(np.array(og_shape) - np.array(new_shape))[0]} \\\n",
    "        \\nPercentage of original dataframe {round(((np.array(og_shape) - np.array(new_shape))[0]/np.array(og_shape))[0] * 100,2)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148805, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validation, test sets\n",
    "training_percent = 0.6\n",
    "validation_percent = training_percent + 0.2\n",
    "# test set is remaining amount\n",
    "\n",
    "train, val, test = np.split(\n",
    "    df_full.sample(frac=1, random_state=42),\n",
    "    [int(training_percent * len(df_full)), int(validation_percent * len(df_full))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(f\"../data/training-set-{today}\")\n",
    "val.to_csv(f\"../data/val-set-{today}\")\n",
    "test.to_csv(f\"../data/test-set-{today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portalanalytics-V3tNXbPg-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
