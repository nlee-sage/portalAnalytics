{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Goal \n","- Establish baseline model"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# Setup\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_decision_forests as tfdf\n","import utils\n","\n","import dtreeviz\n","\n","from matplotlib import pyplot as plt\n","from IPython import display"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# load dataset\n","df = pd.read_csv(\"../data/complete-dataset-20231215.csv\").drop(\n","    columns=[\"Unnamed: 0\"], errors=\"ignore\"\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>TYPE</th>\n","      <th>TABLE</th>\n","      <th>NAME</th>\n","      <th>FILEFORMAT</th>\n","      <th>STUDY</th>\n","      <th>ASSAY</th>\n","      <th>DATATYPE</th>\n","      <th>DATASUBTYPE</th>\n","      <th>RESOURCETYPE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>syn2426151</td>\n","      <td>file</td>\n","      <td>SAGE.PORTAL_RAW.AD</td>\n","      <td>chr1.chop.dosage.gz</td>\n","      <td>txt</td>\n","      <td>ROSMAP</td>\n","      <td>SNParray</td>\n","      <td>genomicVariants</td>\n","      <td>processed</td>\n","      <td>analysis</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>syn2426152</td>\n","      <td>file</td>\n","      <td>SAGE.PORTAL_RAW.AD</td>\n","      <td>chr2.chop.dosage.gz</td>\n","      <td>txt</td>\n","      <td>ROSMAP</td>\n","      <td>SNParray</td>\n","      <td>genomicVariants</td>\n","      <td>processed</td>\n","      <td>analysis</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>syn2426153</td>\n","      <td>file</td>\n","      <td>SAGE.PORTAL_RAW.AD</td>\n","      <td>chr4.chop.dosage.gz</td>\n","      <td>txt</td>\n","      <td>ROSMAP</td>\n","      <td>SNParray</td>\n","      <td>genomicVariants</td>\n","      <td>processed</td>\n","      <td>analysis</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>syn2426154</td>\n","      <td>file</td>\n","      <td>SAGE.PORTAL_RAW.AD</td>\n","      <td>chr8.chop.dosage.gz</td>\n","      <td>txt</td>\n","      <td>ROSMAP</td>\n","      <td>SNParray</td>\n","      <td>genomicVariants</td>\n","      <td>processed</td>\n","      <td>analysis</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>syn2426155</td>\n","      <td>file</td>\n","      <td>SAGE.PORTAL_RAW.AD</td>\n","      <td>chr9.chop.dosage.gz</td>\n","      <td>txt</td>\n","      <td>ROSMAP</td>\n","      <td>SNParray</td>\n","      <td>genomicVariants</td>\n","      <td>processed</td>\n","      <td>analysis</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           ID  TYPE               TABLE                 NAME FILEFORMAT  \\\n","0  syn2426151  file  SAGE.PORTAL_RAW.AD  chr1.chop.dosage.gz        txt   \n","1  syn2426152  file  SAGE.PORTAL_RAW.AD  chr2.chop.dosage.gz        txt   \n","2  syn2426153  file  SAGE.PORTAL_RAW.AD  chr4.chop.dosage.gz        txt   \n","3  syn2426154  file  SAGE.PORTAL_RAW.AD  chr8.chop.dosage.gz        txt   \n","4  syn2426155  file  SAGE.PORTAL_RAW.AD  chr9.chop.dosage.gz        txt   \n","\n","    STUDY     ASSAY         DATATYPE DATASUBTYPE RESOURCETYPE  \n","0  ROSMAP  SNParray  genomicVariants   processed     analysis  \n","1  ROSMAP  SNParray  genomicVariants   processed     analysis  \n","2  ROSMAP  SNParray  genomicVariants   processed     analysis  \n","3  ROSMAP  SNParray  genomicVariants   processed     analysis  \n","4  ROSMAP  SNParray  genomicVariants   processed     analysis  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Look at relationship between dataType and datasubtype"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RESOURCETYPE</th>\n","      <th>FILEFORMAT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>analysis</td>\n","      <td>txt</td>\n","    </tr>\n","    <tr>\n","      <th>73575</th>\n","      <td>analysis</td>\n","      <td>idx</td>\n","    </tr>\n","    <tr>\n","      <th>58850</th>\n","      <td>analysis</td>\n","      <td>rdata</td>\n","    </tr>\n","    <tr>\n","      <th>44063</th>\n","      <td>analysis</td>\n","      <td>raw</td>\n","    </tr>\n","    <tr>\n","      <th>146262</th>\n","      <td>analysis</td>\n","      <td>gzip</td>\n","    </tr>\n","    <tr>\n","      <th>35094</th>\n","      <td>analysis</td>\n","      <td>vcf</td>\n","    </tr>\n","    <tr>\n","      <th>34954</th>\n","      <td>analysis</td>\n","      <td>ppt</td>\n","    </tr>\n","    <tr>\n","      <th>34820</th>\n","      <td>analysis</td>\n","      <td>excel</td>\n","    </tr>\n","    <tr>\n","      <th>34798</th>\n","      <td>analysis</td>\n","      <td>zip</td>\n","    </tr>\n","    <tr>\n","      <th>34794</th>\n","      <td>analysis</td>\n","      <td>pdf</td>\n","    </tr>\n","    <tr>\n","      <th>148804</th>\n","      <td>analysis</td>\n","      <td>bed</td>\n","    </tr>\n","    <tr>\n","      <th>4437</th>\n","      <td>analysis</td>\n","      <td>plink</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>analysis</td>\n","      <td>tsv</td>\n","    </tr>\n","    <tr>\n","      <th>1576</th>\n","      <td>analysis</td>\n","      <td>csv</td>\n","    </tr>\n","    <tr>\n","      <th>4508</th>\n","      <td>experimentalData</td>\n","      <td>sentrixdescriptorfile</td>\n","    </tr>\n","    <tr>\n","      <th>49081</th>\n","      <td>experimentalData</td>\n","      <td>pepxml</td>\n","    </tr>\n","    <tr>\n","      <th>51101</th>\n","      <td>experimentalData</td>\n","      <td>hdf</td>\n","    </tr>\n","    <tr>\n","      <th>54666</th>\n","      <td>experimentalData</td>\n","      <td>png</td>\n","    </tr>\n","    <tr>\n","      <th>55975</th>\n","      <td>experimentalData</td>\n","      <td>vcf</td>\n","    </tr>\n","    <tr>\n","      <th>58284</th>\n","      <td>experimentalData</td>\n","      <td>gzip</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>experimentalData</td>\n","      <td>tsv</td>\n","    </tr>\n","    <tr>\n","      <th>59888</th>\n","      <td>experimentalData</td>\n","      <td>bed</td>\n","    </tr>\n","    <tr>\n","      <th>59889</th>\n","      <td>experimentalData</td>\n","      <td>bim</td>\n","    </tr>\n","    <tr>\n","      <th>59890</th>\n","      <td>experimentalData</td>\n","      <td>fam</td>\n","    </tr>\n","    <tr>\n","      <th>72470</th>\n","      <td>experimentalData</td>\n","      <td>crai</td>\n","    </tr>\n","    <tr>\n","      <th>72485</th>\n","      <td>experimentalData</td>\n","      <td>cram</td>\n","    </tr>\n","    <tr>\n","      <th>84314</th>\n","      <td>experimentalData</td>\n","      <td>tbi</td>\n","    </tr>\n","    <tr>\n","      <th>109862</th>\n","      <td>experimentalData</td>\n","      <td>saf</td>\n","    </tr>\n","    <tr>\n","      <th>119371</th>\n","      <td>experimentalData</td>\n","      <td>bsc</td>\n","    </tr>\n","    <tr>\n","      <th>146184</th>\n","      <td>experimentalData</td>\n","      <td>bigwig</td>\n","    </tr>\n","    <tr>\n","      <th>42488</th>\n","      <td>experimentalData</td>\n","      <td>czi</td>\n","    </tr>\n","    <tr>\n","      <th>42055</th>\n","      <td>experimentalData</td>\n","      <td>xlsx</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>experimentalData</td>\n","      <td>plink</td>\n","    </tr>\n","    <tr>\n","      <th>41499</th>\n","      <td>experimentalData</td>\n","      <td>mtx</td>\n","    </tr>\n","    <tr>\n","      <th>4509</th>\n","      <td>experimentalData</td>\n","      <td>txt</td>\n","    </tr>\n","    <tr>\n","      <th>4510</th>\n","      <td>experimentalData</td>\n","      <td>xml</td>\n","    </tr>\n","    <tr>\n","      <th>4511</th>\n","      <td>experimentalData</td>\n","      <td>jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4534</th>\n","      <td>experimentalData</td>\n","      <td>idat</td>\n","    </tr>\n","    <tr>\n","      <th>4824</th>\n","      <td>experimentalData</td>\n","      <td>cfg</td>\n","    </tr>\n","    <tr>\n","      <th>41504</th>\n","      <td>experimentalData</td>\n","      <td>fasta</td>\n","    </tr>\n","    <tr>\n","      <th>11538</th>\n","      <td>experimentalData</td>\n","      <td>bpm</td>\n","    </tr>\n","    <tr>\n","      <th>12028</th>\n","      <td>experimentalData</td>\n","      <td>db</td>\n","    </tr>\n","    <tr>\n","      <th>11081</th>\n","      <td>experimentalData</td>\n","      <td>locs</td>\n","    </tr>\n","    <tr>\n","      <th>2986</th>\n","      <td>experimentalData</td>\n","      <td>raw</td>\n","    </tr>\n","    <tr>\n","      <th>2978</th>\n","      <td>experimentalData</td>\n","      <td>csv</td>\n","    </tr>\n","    <tr>\n","      <th>34917</th>\n","      <td>experimentalData</td>\n","      <td>excel</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>experimentalData</td>\n","      <td>fastq</td>\n","    </tr>\n","    <tr>\n","      <th>34989</th>\n","      <td>experimentalData</td>\n","      <td>bai</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>experimentalData</td>\n","      <td>bam</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>experimentalData</td>\n","      <td>gct</td>\n","    </tr>\n","    <tr>\n","      <th>38151</th>\n","      <td>experimentalData</td>\n","      <td>rdata</td>\n","    </tr>\n","    <tr>\n","      <th>24478</th>\n","      <td>experimentalData</td>\n","      <td>zip</td>\n","    </tr>\n","    <tr>\n","      <th>35495</th>\n","      <td>experimentalData</td>\n","      <td>tar</td>\n","    </tr>\n","    <tr>\n","      <th>73572</th>\n","      <td>metadata</td>\n","      <td>csv</td>\n","    </tr>\n","    <tr>\n","      <th>141079</th>\n","      <td>metadata</td>\n","      <td>tsv</td>\n","    </tr>\n","    <tr>\n","      <th>143685</th>\n","      <td>metadata</td>\n","      <td>excel</td>\n","    </tr>\n","    <tr>\n","      <th>143689</th>\n","      <td>metadata</td>\n","      <td>txt</td>\n","    </tr>\n","    <tr>\n","      <th>143732</th>\n","      <td>metadata</td>\n","      <td>jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            RESOURCETYPE             FILEFORMAT\n","0               analysis                    txt\n","73575           analysis                    idx\n","58850           analysis                  rdata\n","44063           analysis                    raw\n","146262          analysis                   gzip\n","35094           analysis                    vcf\n","34954           analysis                    ppt\n","34820           analysis                  excel\n","34798           analysis                    zip\n","34794           analysis                    pdf\n","148804          analysis                    bed\n","4437            analysis                  plink\n","22              analysis                    tsv\n","1576            analysis                    csv\n","4508    experimentalData  sentrixdescriptorfile\n","49081   experimentalData                 pepxml\n","51101   experimentalData                    hdf\n","54666   experimentalData                    png\n","55975   experimentalData                    vcf\n","58284   experimentalData                   gzip\n","23      experimentalData                    tsv\n","59888   experimentalData                    bed\n","59889   experimentalData                    bim\n","59890   experimentalData                    fam\n","72470   experimentalData                   crai\n","72485   experimentalData                   cram\n","84314   experimentalData                    tbi\n","109862  experimentalData                    saf\n","119371  experimentalData                    bsc\n","146184  experimentalData                 bigwig\n","42488   experimentalData                    czi\n","42055   experimentalData                   xlsx\n","24      experimentalData                  plink\n","41499   experimentalData                    mtx\n","4509    experimentalData                    txt\n","4510    experimentalData                    xml\n","4511    experimentalData                    jpg\n","4534    experimentalData                   idat\n","4824    experimentalData                    cfg\n","41504   experimentalData                  fasta\n","11538   experimentalData                    bpm\n","12028   experimentalData                     db\n","11081   experimentalData                   locs\n","2986    experimentalData                    raw\n","2978    experimentalData                    csv\n","34917   experimentalData                  excel\n","43      experimentalData                  fastq\n","34989   experimentalData                    bai\n","42      experimentalData                    bam\n","33      experimentalData                    gct\n","38151   experimentalData                  rdata\n","24478   experimentalData                    zip\n","35495   experimentalData                    tar\n","73572           metadata                    csv\n","141079          metadata                    tsv\n","143685          metadata                  excel\n","143689          metadata                    txt\n","143732          metadata                    jpg"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df[['RESOURCETYPE', 'FILEFORMAT']].drop_duplicates().sort_values(by = 'RESOURCETYPE')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found TensorFlow Decision Forests v1.8.1\n"]}],"source":["# Check the version of TensorFlow Decision Forests\n","print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def labeler(dataset, class_label):\n","    # Encode the categorical labels as integers.\n","    #\n","    # Details:\n","    # This stage is necessary if your classification label is represented as a\n","    # string since Keras expects integer classification labels.\n","    # When using `pd_dataframe_to_tf_dataset` (see below), this step can be skipped.\n","\n","    # Name of the label column.\n","    classes = dataset[class_label].unique().tolist()\n","    print(f\"Label classes: {classes}\")\n","\n","    dataset[\"label\"] = dataset[class_label].map(classes.index)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Label classes: ['analysis', 'experimentalData', 'metadata']\n"]}],"source":["class_label = \"RESOURCETYPE\"\n","df = labeler(df, class_label)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["classes = df[class_label].unique().tolist()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train, val, test = utils.create_datasets(df, 0.6, 0.2)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["(89283, 11)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train.shape"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=label_col)\n","val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(val, label=label_col)\n","test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=label_col)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Use 8 thread(s) for training\n","Use /var/folders/p0/5m4pdsm55jn_d5nzbjv6bjf40000gq/T/tmp6r5pw5qn as temporary training directory\n","Reading training dataset...\n","Training tensor examples:\n","Features: {'ID': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'TYPE': <tf.Tensor 'data_1:0' shape=(None,) dtype=string>, 'TABLE': <tf.Tensor 'data_2:0' shape=(None,) dtype=string>, 'NAME': <tf.Tensor 'data_3:0' shape=(None,) dtype=string>, 'FILEFORMAT': <tf.Tensor 'data_4:0' shape=(None,) dtype=string>, 'STUDY': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'ASSAY': <tf.Tensor 'data_6:0' shape=(None,) dtype=string>, 'DATATYPE': <tf.Tensor 'data_7:0' shape=(None,) dtype=string>, 'DATASUBTYPE': <tf.Tensor 'data_8:0' shape=(None,) dtype=string>, 'label': <tf.Tensor 'data_9:0' shape=(None,) dtype=int64>}\n","Label: Tensor(\"data_10:0\", shape=(None,), dtype=int64)\n","Weights: None\n","Normalized tensor features:\n"," {'ID': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'TYPE': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_1:0' shape=(None,) dtype=string>), 'TABLE': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_2:0' shape=(None,) dtype=string>), 'NAME': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_3:0' shape=(None,) dtype=string>), 'FILEFORMAT': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_4:0' shape=(None,) dtype=string>), 'STUDY': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>), 'ASSAY': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_6:0' shape=(None,) dtype=string>), 'DATATYPE': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_7:0' shape=(None,) dtype=string>), 'DATASUBTYPE': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_8:0' shape=(None,) dtype=string>), 'label': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>)}\n","Training dataset read in 0:00:00.398945. Found 89283 examples.\n","Training model...\n"]},{"name":"stderr","output_type":"stream","text":["[INFO 23-12-15 15:59:13.3307 PST kernel.cc:771] Start Yggdrasil model training\n","[INFO 23-12-15 15:59:13.3308 PST kernel.cc:772] Collect training examples\n","[INFO 23-12-15 15:59:13.3309 PST kernel.cc:785] Dataspec guide:\n","column_guides {\n","  column_name_pattern: \"^__LABEL$\"\n","  type: CATEGORICAL\n","  categorial {\n","    min_vocab_frequency: 0\n","    max_vocab_count: -1\n","  }\n","}\n","default_column_guide {\n","  categorial {\n","    max_vocab_count: 2000\n","  }\n","  discretized_numerical {\n","    maximum_num_bins: 255\n","  }\n","}\n","ignore_columns_without_guides: false\n","detect_numerical_as_discretized_numerical: false\n","\n","[INFO 23-12-15 15:59:13.3310 PST kernel.cc:391] Number of batches: 90\n","[INFO 23-12-15 15:59:13.3310 PST kernel.cc:392] Number of examples: 89283\n","[INFO 23-12-15 15:59:13.3651 PST data_spec_inference.cc:305] 26 item(s) have been pruned (i.e. they are considered out of dictionary) for the column ASSAY (27 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.3652 PST data_spec_inference.cc:305] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column DATATYPE (11 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.3652 PST data_spec_inference.cc:305] 12 item(s) have been pruned (i.e. they are considered out of dictionary) for the column FILEFORMAT (28 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.3829 PST data_spec_inference.cc:305] 89283 item(s) have been pruned (i.e. they are considered out of dictionary) for the column ID (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.4214 PST data_spec_inference.cc:305] 88279 item(s) have been pruned (i.e. they are considered out of dictionary) for the column NAME (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.4363 PST data_spec_inference.cc:305] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column STUDY (81 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n","[INFO 23-12-15 15:59:13.4612 PST kernel.cc:792] Training dataset:\n","Number of records: 89283\n","Number of columns: 11\n","\n","Number of columns by type:\n","\tCATEGORICAL: 10 (90.9091%)\n","\tNUMERICAL: 1 (9.09091%)\n","\n","Columns:\n","\n","CATEGORICAL: 10 (90.9091%)\n","\t0: \"ASSAY\" CATEGORICAL has-dict vocab-size:28 num-oods:42 (0.0470414%) most-frequent:\"RNA-seq\" 35895 (40.2036%)\n","\t1: \"DATASUBTYPE\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"raw\" 64511 (72.2545%)\n","\t2: \"DATATYPE\" CATEGORICAL has-dict vocab-size:12 num-oods:4 (0.00448014%) most-frequent:\"geneExpression\" 45979 (51.498%)\n","\t3: \"FILEFORMAT\" CATEGORICAL has-dict vocab-size:29 num-oods:20 (0.0224007%) most-frequent:\"fastq\" 34690 (38.854%)\n","\t4: \"ID\" CATEGORICAL has-dict vocab-size:1 num-oods:89283 (100%)\n","\t5: \"NAME\" CATEGORICAL has-dict vocab-size:4 num-oods:89197 (99.9037%) most-frequent:\"<OOD>\" 89197 (99.9037%)\n","\t6: \"STUDY\" CATEGORICAL has-dict vocab-size:82 num-oods:48 (0.0537616%) most-frequent:\"ROSMAP\" 19918 (22.3088%)\n","\t7: \"TABLE\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"SAGE.PORTAL_RAW.AD\" 86162 (96.5044%)\n","\t8: \"TYPE\" CATEGORICAL has-dict vocab-size:2 zero-ood-items most-frequent:\"file\" 89283 (100%)\n","\t9: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n","\n","NUMERICAL: 1 (9.09091%)\n","\t10: \"label\" NUMERICAL mean:0.902523 min:0 max:2 sd:0.298675\n","\n","Terminology:\n","\tnas: Number of non-available (i.e. missing) values.\n","\tood: Out of dictionary.\n","\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n","\ttokenized: The attribute value is obtained through tokenization.\n","\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n","\tvocab-size: Number of unique values.\n","\n","[INFO 23-12-15 15:59:13.4613 PST kernel.cc:808] Configure learner\n","[INFO 23-12-15 15:59:13.4615 PST kernel.cc:822] Training config:\n","learner: \"RANDOM_FOREST\"\n","features: \"^ASSAY$\"\n","features: \"^DATASUBTYPE$\"\n","features: \"^DATATYPE$\"\n","features: \"^FILEFORMAT$\"\n","features: \"^ID$\"\n","features: \"^NAME$\"\n","features: \"^STUDY$\"\n","features: \"^TABLE$\"\n","features: \"^TYPE$\"\n","features: \"^label$\"\n","label: \"^__LABEL$\"\n","task: CLASSIFICATION\n","random_seed: 123456\n","metadata {\n","  framework: \"TF Keras\"\n","}\n","pure_serving_model: false\n","[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n","  num_trees: 300\n","  decision_tree {\n","    max_depth: 16\n","    min_examples: 5\n","    in_split_min_examples_check: true\n","    keep_non_leaf_label_distribution: true\n","    num_candidate_attributes: 0\n","    missing_value_policy: GLOBAL_IMPUTATION\n","    allow_na_conditions: false\n","    categorical_set_greedy_forward {\n","      sampling: 0.1\n","      max_num_items: -1\n","      min_item_frequency: 1\n","    }\n","    growing_strategy_local {\n","    }\n","    categorical {\n","      cart {\n","      }\n","    }\n","    axis_aligned_split {\n","    }\n","    internal {\n","      sorting_strategy: PRESORTED\n","    }\n","    uplift {\n","      min_examples_in_treatment: 5\n","      split_score: KULLBACK_LEIBLER\n","    }\n","  }\n","  winner_take_all_inference: true\n","  compute_oob_performances: true\n","  compute_oob_variable_importances: false\n","  num_oob_variable_importances_permutations: 1\n","  bootstrap_training_dataset: true\n","  bootstrap_size_ratio: 1\n","  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n","  sampling_with_replacement: true\n","}\n","\n","[INFO 23-12-15 15:59:13.4615 PST kernel.cc:825] Deployment config:\n","cache_path: \"/var/folders/p0/5m4pdsm55jn_d5nzbjv6bjf40000gq/T/tmp6r5pw5qn/working_cache\"\n","num_threads: 8\n","try_resume_training: true\n","\n","[INFO 23-12-15 15:59:13.4616 PST kernel.cc:887] Train model\n","[INFO 23-12-15 15:59:13.4617 PST random_forest.cc:416] Training random forest on 89283 example(s) and 10 feature(s).\n","[INFO 23-12-15 15:59:13.4834 PST random_forest.cc:802] Training of tree  1/300 (tree index:2) done accuracy:1 logloss:0\n","[INFO 23-12-15 15:59:13.5099 PST random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.999943 logloss:0.000871586\n","[INFO 23-12-15 15:59:13.5384 PST random_forest.cc:802] Training of tree  21/300 (tree index:22) done accuracy:0.999989 logloss:5.30298e-05\n","[INFO 23-12-15 15:59:13.5631 PST random_forest.cc:802] Training of tree  31/300 (tree index:31) done accuracy:0.999989 logloss:4.99181e-05\n","[INFO 23-12-15 15:59:13.5912 PST random_forest.cc:802] Training of tree  42/300 (tree index:40) done accuracy:0.999978 logloss:5.5132e-05\n","[INFO 23-12-15 15:59:13.6219 PST random_forest.cc:802] Training of tree  52/300 (tree index:48) done accuracy:0.999978 logloss:6.09438e-05\n","[INFO 23-12-15 15:59:13.6473 PST random_forest.cc:802] Training of tree  62/300 (tree index:62) done accuracy:0.999978 logloss:5.67721e-05\n","[INFO 23-12-15 15:59:13.6753 PST random_forest.cc:802] Training of tree  72/300 (tree index:71) done accuracy:0.999989 logloss:5.41792e-05\n","[INFO 23-12-15 15:59:13.7037 PST random_forest.cc:802] Training of tree  82/300 (tree index:81) done accuracy:0.999989 logloss:4.87057e-05\n","[INFO 23-12-15 15:59:13.7279 PST random_forest.cc:802] Training of tree  92/300 (tree index:89) done accuracy:0.999989 logloss:5.035e-05\n","[INFO 23-12-15 15:59:13.7555 PST random_forest.cc:802] Training of tree  103/300 (tree index:103) done accuracy:0.999989 logloss:4.73058e-05\n","[INFO 23-12-15 15:59:13.7823 PST random_forest.cc:802] Training of tree  113/300 (tree index:113) done accuracy:0.999989 logloss:4.76637e-05\n","[INFO 23-12-15 15:59:13.8086 PST random_forest.cc:802] Training of tree  124/300 (tree index:123) done accuracy:0.999989 logloss:4.72396e-05\n","[INFO 23-12-15 15:59:13.8375 PST random_forest.cc:802] Training of tree  134/300 (tree index:133) done accuracy:0.999989 logloss:4.54142e-05\n","[INFO 23-12-15 15:59:13.8674 PST random_forest.cc:802] Training of tree  144/300 (tree index:144) done accuracy:0.999989 logloss:4.37117e-05\n","[INFO 23-12-15 15:59:13.8962 PST random_forest.cc:802] Training of tree  154/300 (tree index:153) done accuracy:0.999989 logloss:4.25206e-05\n","[INFO 23-12-15 15:59:13.9239 PST random_forest.cc:802] Training of tree  165/300 (tree index:164) done accuracy:0.999989 logloss:4.01224e-05\n","[INFO 23-12-15 15:59:13.9531 PST random_forest.cc:802] Training of tree  175/300 (tree index:177) done accuracy:0.999989 logloss:3.91155e-05\n","[INFO 23-12-15 15:59:13.9797 PST random_forest.cc:802] Training of tree  185/300 (tree index:182) done accuracy:0.999989 logloss:3.94795e-05\n","[INFO 23-12-15 15:59:14.0083 PST random_forest.cc:802] Training of tree  195/300 (tree index:194) done accuracy:0.999989 logloss:3.94134e-05\n","[INFO 23-12-15 15:59:14.0339 PST random_forest.cc:802] Training of tree  205/300 (tree index:205) done accuracy:0.999989 logloss:3.77905e-05\n","[INFO 23-12-15 15:59:14.0599 PST random_forest.cc:802] Training of tree  215/300 (tree index:216) done accuracy:0.999989 logloss:3.73112e-05\n","[INFO 23-12-15 15:59:14.0932 PST random_forest.cc:802] Training of tree  225/300 (tree index:221) done accuracy:0.999989 logloss:3.87071e-05\n","[INFO 23-12-15 15:59:14.1213 PST random_forest.cc:802] Training of tree  235/300 (tree index:235) done accuracy:0.999989 logloss:3.75805e-05\n","[INFO 23-12-15 15:59:14.1474 PST random_forest.cc:802] Training of tree  245/300 (tree index:245) done accuracy:0.999989 logloss:3.76194e-05\n","[INFO 23-12-15 15:59:14.1754 PST random_forest.cc:802] Training of tree  255/300 (tree index:256) done accuracy:0.999989 logloss:3.64683e-05\n","[INFO 23-12-15 15:59:14.1997 PST random_forest.cc:802] Training of tree  265/300 (tree index:261) done accuracy:0.999989 logloss:3.67551e-05\n","[INFO 23-12-15 15:59:14.2293 PST random_forest.cc:802] Training of tree  275/300 (tree index:274) done accuracy:0.999989 logloss:3.67757e-05\n","[INFO 23-12-15 15:59:14.2590 PST random_forest.cc:802] Training of tree  285/300 (tree index:284) done accuracy:0.999989 logloss:3.62977e-05\n","[INFO 23-12-15 15:59:14.2837 PST random_forest.cc:802] Training of tree  295/300 (tree index:292) done accuracy:0.999989 logloss:3.56466e-05\n","[INFO 23-12-15 15:59:14.2947 PST random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.999989 logloss:3.58029e-05\n","[INFO 23-12-15 15:59:14.2948 PST random_forest.cc:882] Final OOB metrics: accuracy:0.999989 logloss:3.58029e-05\n","[INFO 23-12-15 15:59:14.2956 PST kernel.cc:919] Export model in log directory: /var/folders/p0/5m4pdsm55jn_d5nzbjv6bjf40000gq/T/tmp6r5pw5qn with prefix 9935bda791ff44da\n","[INFO 23-12-15 15:59:14.2987 PST kernel.cc:937] Save model in resources\n","[INFO 23-12-15 15:59:14.3001 PST abstract_model.cc:881] Model self evaluation:\n","Number of predictions (without weights): 89283\n","Number of predictions (with weights): 89283\n","Task: CLASSIFICATION\n","Label: __LABEL\n","\n","Accuracy: 0.999989  CI95[W][0.999947 0.999999]\n","LogLoss: : 3.58029e-05\n","ErrorRate: : 1.12057e-05\n","\n","Default Accuracy: : 0.901291\n","Default LogLoss: : 0.325978\n","Default ErrorRate: : 0.0987086\n","\n","Confusion Table:\n","truth\\prediction\n","      1      2   3\n","1  8758      0   0\n","2     0  80470   0\n","3     0      1  54\n","Total: 89283\n","\n","\n","[INFO 23-12-15 15:59:14.3087 PST kernel.cc:1233] Loading model from path /var/folders/p0/5m4pdsm55jn_d5nzbjv6bjf40000gq/T/tmp6r5pw5qn/model/ with prefix 9935bda791ff44da\n","[INFO 23-12-15 15:59:14.3133 PST decision_forest.cc:660] Model loaded with 300 root(s), 2912 node(s), and 7 input feature(s).\n","[INFO 23-12-15 15:59:14.3134 PST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n","[INFO 23-12-15 15:59:14.3134 PST kernel.cc:1061] Use fast generic engine\n"]},{"name":"stdout","output_type":"stream","text":["Model trained in 0:00:00.987342\n","Compiling model...\n","Model compiled.\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x2931f5b10>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Specify the model.\n","model_1 = tfdf.keras.RandomForestModel(verbose=2)\n","\n","# Train the model.\n","model_1.fit(train_ds)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["30/30 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","\n","loss: 0.0000\n","accuracy: 1.0000\n"]}],"source":["model_1.compile(metrics=[\"accuracy\"])\n","evaluation = model_1.evaluate(test_ds, return_dict=True)\n","print()\n","\n","for name, value in evaluation.items():\n","    print(f\"{name}: {value:.4f}\")"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["# Tell dtreeviz about training data and model\n","features = [f.name for f in model_1.make_inspector().features()]\n","viz_model_1 = dtreeviz.model(\n","    model_1,\n","    tree_index=3,\n","    X_train=train[features],\n","    y_train=train[label_col],\n","    feature_names=features,\n","    target_name=label_col,\n","    class_names=classes,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_1.save(\"/tmp/my_saved_model\")"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["with open('./tree.html', 'w', encoding = 'utf-8') as f: \n","    f.write(\n","        str(\n","            BeautifulSoup(\n","                tfdf.model_plotter.plot_model(model_1, tree_idx=0, max_depth=3),\n","                \"html.parser\").prettify()))"]}],"metadata":{"kernelspec":{"display_name":"portalanalytics-V3tNXbPg-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
